{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NNL2MDOzWirt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from lightgbm import LGBMRegressor, Dataset\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import ExtraTreesRegressor,RandomForestRegressor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HjsmHyldsao0",
    "outputId": "be48d607-f45f-4402-8be6-8e70fa04a783"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rXIkO6pHsbr2",
    "outputId": "ad637a0c-978c-434c-d6a7-fa46d2ef3827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Main Data\n"
     ]
    }
   ],
   "source": [
    "########################### Load Data\n",
    "#################################################################################\n",
    "print('Load Main Data')\n",
    "train_df = pd.read_csv(r'/content/drive/MyDrive/AAIC/Assignment - 22 Self Case Study 1/sales_train_evaluation.csv')\n",
    "prices_df = pd.read_csv(r'/content/drive/MyDrive/AAIC/Assignment - 22 Self Case Study 1/sell_prices.csv')\n",
    "calendar_df = pd.read_csv(r'/content/drive/MyDrive/AAIC/Assignment - 22 Self Case Study 1/calendar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5aZACYzJ1hOo"
   },
   "outputs": [],
   "source": [
    "## Found this code snippet in one of the discussion notebooks, to downcast the int and float data types\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: \n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2koaHUM1i1r",
    "outputId": "88d4063b-721a-4238-fbf1-faea927f8664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.12 Mb (41.9% reduction)\n",
      "Mem. usage decreased to 130.48 Mb (37.5% reduction)\n",
      "Mem. usage decreased to 96.13 Mb (78.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "calendar_df = reduce_mem_usage(calendar_df)\n",
    "\n",
    "prices_df = reduce_mem_usage(prices_df)\n",
    "\n",
    "train_df = reduce_mem_usage(train_df)\n",
    "\n",
    "# submission = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sample_submission.csv')\n",
    "# submission = reduce_mem_usage(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "nZ0IeCX3SChY"
   },
   "outputs": [],
   "source": [
    "def function_1(test):\n",
    "    # We are creating new features required for the prediction for days from 1942 till 1969\n",
    "    for day in range(1942,1942+28):\n",
    "      test['d_' + str(day)] = np.int32(0)\n",
    "\n",
    "    # We are transforming our Time Series Data so that we can apply supervised ml problem techniques\n",
    "    data = pd.melt(test, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],\n",
    "              var_name='day', value_name='demand').dropna()  \n",
    "\n",
    "    ## Merging all the files so that we have them in 1 place to make features\n",
    "    data = data.merge(calendar_df, left_on='day', right_on='d')\n",
    "    data = data.merge(prices_df,on=['store_id','item_id', 'wm_yr_wk'], how='left')\n",
    "\n",
    "    ## Imputing Null in the sell price with the mean of the product id\n",
    "    data['sell_price'].fillna(data.groupby('id')['sell_price'].transform('mean'), inplace=True)\n",
    "\n",
    "    #Feature 1 :: we are removing  _ from ex d_101 to get the day number i.e 101\n",
    "    data['day'] = data['day'].apply(lambda x: x.split('_')[1]).astype(np.int16)\n",
    "\n",
    "    #since weekday's are represented as wday with numbers and d is a duplicate column.\n",
    "    data.drop(['d','weekday'], axis=1, inplace=True)\n",
    "\n",
    "    nan_features = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "    #Imputing Nan\n",
    "    for feature in nan_features:\n",
    "        data[feature].fillna('NA', inplace = True)\n",
    "\n",
    "\n",
    "    ##loading the dict which contains the mappings of the Label Encoders   \n",
    "    all_label_dicts = pickle.load(open(\"/content/drive/MyDrive/AAIC/Assignment - 22 Self Case Study 1/all_label_dicts.p\", \"rb\"))\n",
    "\n",
    "    for feature in list(all_label_dicts.keys()):\n",
    "      feat_dict = all_label_dicts[feature]\n",
    "      data[feature] = data[feature].map(feat_dict)\n",
    "\n",
    "    data['lag_28'] = data.groupby(['id'])['demand'].transform(lambda x: x.shift(28))\n",
    "    data['lag_56'] = data.groupby(['id'])['demand'].transform(lambda x: x.shift(56))\n",
    "\n",
    "    data['rolling_mean_7']   = data.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(7).mean())\n",
    "    data['rolling_std_7']    = data.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(7).std())\n",
    "\n",
    "    data['rolling_mean_56']  = data.groupby(['id'])['demand'].transform(lambda x: x.shift(56).rolling(7).mean())\n",
    "    data['rolling_std_56']    = data.groupby(['id'])['demand'].transform(lambda x: x.shift(56).rolling(7).std())\n",
    "\n",
    "    ## Creating time based features\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data['year'] = data['date'].dt.year\n",
    "    data['month'] = data['date'].dt.month\n",
    "    data['week'] = data['date'].dt.week\n",
    "    data['day_of_date'] = data['date'].dt.day\n",
    "    data['dayofweek'] = data['date'].dt.dayofweek\n",
    "\n",
    "    data['days'] = data['day']\n",
    "    data['day'] = data['day_of_date']\n",
    "\n",
    "    ## Weekend feature\n",
    "    def weekend(arg):\n",
    "        if arg==5 or arg==6:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    data['isweekend'] = data['dayofweek'].apply(weekend)\n",
    "\n",
    "    data.fillna(0,inplace=True)\n",
    "\n",
    "    best_model = pickle.load(open(\"/content/drive/MyDrive/AAIC/Assignment - 22 Self Case Study 1/best_model.p\", \"rb\"))\n",
    "\n",
    "    features = ['days','day', 'wm_yr_wk', 'wday', 'month', 'year', 'event_name_1',\n",
    "       'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX',\n",
    "       'snap_WI', 'sell_price', 'week',\n",
    "       'isweekend','lag_28', 'lag_56', 'rolling_mean_7', 'rolling_std_7',\n",
    "       'rolling_mean_56', 'rolling_std_56']\n",
    "\n",
    "\n",
    "\n",
    "    # We are splitting the data for validation and test and then predicting it's value\n",
    "    Val = data[(data['days']>1913) & (data['days']<1942)]\n",
    "    pred_val_array = best_model.predict(Val[features])\n",
    "\n",
    "    Test = data[data['days']>1941]\n",
    "    pred_test_array = best_model.predict(Test[features])\n",
    "    \n",
    "\n",
    "    # We are then reshaping the predicted value\n",
    "    pred_val_array = np.reshape(pred_val_array, (-1, 28),order = 'F')\n",
    "    pred_test_array = np.reshape(pred_test_array, (-1, 28),order = 'F')\n",
    "\n",
    "    cols = ['F'+str(i) for i in range(1,29)]\n",
    "\n",
    "    vals = pd.concat([pd.DataFrame([test['id']], index=[0]),pd.DataFrame(pred_val_array, columns=cols)],axis=1).rename(columns={0:'ID'})\n",
    "    vals['ID'] = vals['ID'].apply(lambda x: x.replace('evaluation','validation'))\n",
    "    tst = pd.concat([pd.DataFrame([test['id']], index=[0]),pd.DataFrame(pred_test_array, columns=cols)],axis=1).rename(columns={0:'ID'})\n",
    "\n",
    "    return vals, tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "id": "tgvGilEBaVRr",
    "outputId": "e0acee67-0b03-41b2-e5da-3b499cd5685d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>d_5</th>\n",
       "      <th>d_6</th>\n",
       "      <th>d_7</th>\n",
       "      <th>d_8</th>\n",
       "      <th>d_9</th>\n",
       "      <th>d_10</th>\n",
       "      <th>d_11</th>\n",
       "      <th>d_12</th>\n",
       "      <th>d_13</th>\n",
       "      <th>d_14</th>\n",
       "      <th>d_15</th>\n",
       "      <th>d_16</th>\n",
       "      <th>d_17</th>\n",
       "      <th>d_18</th>\n",
       "      <th>d_19</th>\n",
       "      <th>d_20</th>\n",
       "      <th>d_21</th>\n",
       "      <th>d_22</th>\n",
       "      <th>d_23</th>\n",
       "      <th>d_24</th>\n",
       "      <th>d_25</th>\n",
       "      <th>d_26</th>\n",
       "      <th>d_27</th>\n",
       "      <th>d_28</th>\n",
       "      <th>d_29</th>\n",
       "      <th>d_30</th>\n",
       "      <th>d_31</th>\n",
       "      <th>d_32</th>\n",
       "      <th>d_33</th>\n",
       "      <th>d_34</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1902</th>\n",
       "      <th>d_1903</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "      <th>d_1914</th>\n",
       "      <th>d_1915</th>\n",
       "      <th>d_1916</th>\n",
       "      <th>d_1917</th>\n",
       "      <th>d_1918</th>\n",
       "      <th>d_1919</th>\n",
       "      <th>d_1920</th>\n",
       "      <th>d_1921</th>\n",
       "      <th>d_1922</th>\n",
       "      <th>d_1923</th>\n",
       "      <th>d_1924</th>\n",
       "      <th>d_1925</th>\n",
       "      <th>d_1926</th>\n",
       "      <th>d_1927</th>\n",
       "      <th>d_1928</th>\n",
       "      <th>d_1929</th>\n",
       "      <th>d_1930</th>\n",
       "      <th>d_1931</th>\n",
       "      <th>d_1932</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_139_WI_1_evaluation</td>\n",
       "      <td>HOBBIES_1_139</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>WI_1</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1947 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id  ... d_1940 d_1941\n",
       "0  HOBBIES_1_139_WI_1_evaluation  HOBBIES_1_139  ...      0      0\n",
       "\n",
       "[1 rows x 1947 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = train_df.sample(random_state=13).reset_index(drop=True)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "uCUWvQSfa5BD",
    "outputId": "8a829248-851c-4c88-f87e-2f91606f085b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast sales from days 1914 till 1941 is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_139_WI_1_validation</td>\n",
       "      <td>0.542993</td>\n",
       "      <td>0.449291</td>\n",
       "      <td>0.434987</td>\n",
       "      <td>0.591991</td>\n",
       "      <td>0.581451</td>\n",
       "      <td>0.841939</td>\n",
       "      <td>0.797673</td>\n",
       "      <td>0.611378</td>\n",
       "      <td>0.470493</td>\n",
       "      <td>0.512672</td>\n",
       "      <td>0.416342</td>\n",
       "      <td>0.464339</td>\n",
       "      <td>0.501517</td>\n",
       "      <td>0.382907</td>\n",
       "      <td>0.364379</td>\n",
       "      <td>0.31791</td>\n",
       "      <td>0.334058</td>\n",
       "      <td>0.311306</td>\n",
       "      <td>0.338624</td>\n",
       "      <td>0.438959</td>\n",
       "      <td>0.44208</td>\n",
       "      <td>0.459217</td>\n",
       "      <td>0.520918</td>\n",
       "      <td>0.444174</td>\n",
       "      <td>0.512672</td>\n",
       "      <td>0.662136</td>\n",
       "      <td>0.72648</td>\n",
       "      <td>0.756494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ID        F1  ...      F27       F28\n",
       "0  HOBBIES_1_139_WI_1_validation  0.542993  ...  0.72648  0.756494\n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forecast sales from days 1942 till 1969 is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_139_WI_1_evaluation</td>\n",
       "      <td>0.51513</td>\n",
       "      <td>0.384972</td>\n",
       "      <td>0.460292</td>\n",
       "      <td>0.409489</td>\n",
       "      <td>0.361414</td>\n",
       "      <td>0.418519</td>\n",
       "      <td>0.418519</td>\n",
       "      <td>0.350823</td>\n",
       "      <td>0.30973</td>\n",
       "      <td>0.358559</td>\n",
       "      <td>0.466423</td>\n",
       "      <td>0.47653</td>\n",
       "      <td>0.536566</td>\n",
       "      <td>0.50746</td>\n",
       "      <td>0.434537</td>\n",
       "      <td>0.393107</td>\n",
       "      <td>0.465901</td>\n",
       "      <td>0.328942</td>\n",
       "      <td>0.358458</td>\n",
       "      <td>0.521976</td>\n",
       "      <td>0.504365</td>\n",
       "      <td>0.428928</td>\n",
       "      <td>0.361095</td>\n",
       "      <td>0.314402</td>\n",
       "      <td>0.33785</td>\n",
       "      <td>0.467537</td>\n",
       "      <td>0.431728</td>\n",
       "      <td>0.426228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ID       F1  ...       F27       F28\n",
       "0  HOBBIES_1_139_WI_1_evaluation  0.51513  ...  0.431728  0.426228\n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.23 s, sys: 24.7 ms, total: 2.26 s\n",
      "Wall time: 2.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Val_op,Test_op = function_1(test)\n",
    "print('Forecast sales from days 1914 till 1941 is:')\n",
    "display(Val_op)\n",
    "print('\\nForecast sales from days 1942 till 1969 is:')\n",
    "display(Test_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2QbBEcsiDlk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "r_EnoIiOiDjY"
   },
   "outputs": [],
   "source": [
    "def function_2(test,test_op):\n",
    "    # We are creating new features required for the prediction for days from 1942 till 1969\n",
    "    for day in range(1942,1942+28):\n",
    "      test['d_' + str(day)] = np.int32(0)\n",
    "\n",
    "    # We are transforming our Time Series Data so that we can apply supervised ml problem techniques\n",
    "    data = pd.melt(test, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],\n",
    "              var_name='day', value_name='demand').dropna()  \n",
    "\n",
    "    ## Merging all the files so that we have them in 1 place to make features\n",
    "    data = data.merge(calendar_df, left_on='day', right_on='d')\n",
    "    data = data.merge(prices_df,on=['store_id','item_id', 'wm_yr_wk'], how='left')\n",
    "\n",
    "    ## Imputing Null in the sell price with the mean of the product id\n",
    "    data['sell_price'].fillna(data.groupby('id')['sell_price'].transform('mean'), inplace=True)\n",
    "\n",
    "    #Feature 1 :: we are removing  _ from ex d_101 to get the day number i.e 101\n",
    "    data['day'] = data['day'].apply(lambda x: x.split('_')[1]).astype(np.int16)\n",
    "\n",
    "    #since weekday's are represented as wday with numbers and d is a duplicate column.\n",
    "    data.drop(['d','weekday'], axis=1, inplace=True)\n",
    "\n",
    "    nan_features = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "    #Imputing Nan\n",
    "    for feature in nan_features:\n",
    "        data[feature].fillna('NA', inplace = True)\n",
    "\n",
    "\n",
    "    ##loading the dict which contains the mappings of the Label Encoders   \n",
    "    all_label_dicts = pickle.load(open(\"/content/drive/MyDrive/AAIC/Assignment - 22 Self Case Study 1/all_label_dicts.p\", \"rb\"))\n",
    "\n",
    "    for feature in list(all_label_dicts.keys()):\n",
    "      feat_dict = all_label_dicts[feature]\n",
    "      data[feature] = data[feature].map(feat_dict)\n",
    "\n",
    "    data['lag_28'] = data.groupby(['id'])['demand'].transform(lambda x: x.shift(28))\n",
    "    data['lag_56'] = data.groupby(['id'])['demand'].transform(lambda x: x.shift(56))\n",
    "\n",
    "    data['rolling_mean_7']   = data.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(7).mean())\n",
    "    data['rolling_std_7']    = data.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(7).std())\n",
    "\n",
    "    data['rolling_mean_56']  = data.groupby(['id'])['demand'].transform(lambda x: x.shift(56).rolling(7).mean())\n",
    "    data['rolling_std_56']    = data.groupby(['id'])['demand'].transform(lambda x: x.shift(56).rolling(7).std())\n",
    "\n",
    "    ## Creating time based features\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data['year'] = data['date'].dt.year\n",
    "    data['month'] = data['date'].dt.month\n",
    "    data['week'] = data['date'].dt.week\n",
    "    data['day_of_date'] = data['date'].dt.day\n",
    "    data['dayofweek'] = data['date'].dt.dayofweek\n",
    "\n",
    "    data['days'] = data['day']\n",
    "    data['day'] = data['day_of_date']\n",
    "\n",
    "    ## Weekend feature\n",
    "    def weekend(arg):\n",
    "        if arg==5 or arg==6:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    data['isweekend'] = data['dayofweek'].apply(weekend)\n",
    "\n",
    "    data.fillna(0,inplace=True)\n",
    "\n",
    "    best_model = pickle.load(open(\"/content/drive/MyDrive/AAIC/Assignment - 22 Self Case Study 1/best_model.p\", \"rb\"))\n",
    "\n",
    "    features = ['days','day', 'wm_yr_wk', 'wday', 'month', 'year', 'event_name_1',\n",
    "       'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX',\n",
    "       'snap_WI', 'sell_price', 'week',\n",
    "       'isweekend','lag_28', 'lag_56', 'rolling_mean_7', 'rolling_std_7',\n",
    "       'rolling_mean_56', 'rolling_std_56']\n",
    "\n",
    "\n",
    "\n",
    "    # Rmse for Test\n",
    "    Test = data[(data['days']>1941)]\n",
    "    pred_test_array = best_model.predict(Test[features])\n",
    "\n",
    "    # We are then reshaping for calculating the rmse value\n",
    "    y_pred = np.reshape(pred_test_array, (-1, 28),order = 'F')\n",
    "\n",
    "    rmse_test = mse(y_true=test_op, y_pred=y_pred, squared=False)\n",
    "    \n",
    "    return rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "Vl98iv9XiQXi"
   },
   "outputs": [],
   "source": [
    "rmse = function_2(test.iloc[:,:-28],test.iloc[:,-28:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0H7DarPiQVT",
    "outputId": "e3b187f6-8270-41fc-bcf6-e38c6373f564"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE of the test set is 0.42466958334746324\n"
     ]
    }
   ],
   "source": [
    "print(\"The RMSE of the test set is\",rmse)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "name": "Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
